import json
import numpy as np
import pandas as pd
from sklearn.ensemble import AdaBoostClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
import pickle
import joblib
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_curve, auc
ALL_PERMISSIONS = open('../permissions.txt', 'r').readlines()
ALL_OPECODES_1 = open('../opcodes.txt','r').readlines()
ALL_OPECODES=[]
ALL_OPCODES=[]
ALL_STRINGS=[]
for x in range(len(ALL_OPECODES_1)):
    ALL_OPECODES.append(ALL_OPECODES_1[x].strip())
    
def get_metrics(model, xTest, yTest):
    predictions = model.predict(xTest)
    
    # Calculating the accuracy of classifier
    print(f"Accuracy of the classifier is: {accuracy_score(yTest, predictions)}")
    print()
    # confusion_matrix funnction a matrix containing the summary of predictions
    print(confusion_matrix(yTest, predictions))
    # plot_confusion_matrix function is used to visualize the confusion matrix
    plot_confusion_matrix(model, xTest, yTest)
    plt.show()
    
    # Calculating the precision score of classifier
    print()
    print(f"Precision Score of the classifier is: {precision_score(yTest, predictions)}")
    
    # Calculating the recall score of classifier
    print()
    print(f"Recall Score of the classifier is: {recall_score(yTest, predictions)}")
    
    class_probabilities = model.predict_proba(xTest)
    preds = class_probabilities[:, 1]
    fpr, tpr, threshold = roc_curve(yTest, preds)
    roc_auc = auc(fpr, tpr)
    # Printing AUC
    print()
    print(f"AUC for our classifier is: {roc_auc}")
    # Plotting the ROC
    plt.title('Receiver Operating Characteristic')
    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
    plt.legend(loc = 'lower right')
    plt.plot([0, 1], [0, 1],'r--')
    plt.xlim([0, 1])
    plt.ylim([0, 1])
    plt.ylabel('True Positive Rate')
    plt.xlabel('False Positive Rate')
    plt.show()

def get_permission_matrix(permissions):
    print(str(datarow['Package name']))
    perm_vector = np.zeros(len(ALL_PERMISSIONS))
    print(perm_vector.shape)
    for permission in permissions:
        for i in range(len(perm_vector)):
            if ALL_PERMISSIONS[i].strip() == permission:
                print(ALL_PERMISSIONS[i])
                print('Got permission')
                perm_vector[i] = 1
            else:
                perm_vector[i] = 0

    print(perm_vector)
    return perm_vector

def generate_opcode_vector(dictOpCodes,ALL_OPECODES):
    print(str(datarow['Package name']))
    opcode_vec = []
    #print(perm_vector.shape)
    for op in ALL_OPECODES:
        try:
            opcode_vec.append(dictOpCodes[op])
        except Exception as err:
            opcode_vec.append(0)
            # print(err)

    # print(opcode_vec)
    return opcode_vec

def generate_opstrings_vector(dictOpStrings, ALL_STRINGS):
    opstring_vec = []
    for opstring in ALL_STRINGS:
        try:
            opstring_vec.append(dictOpStrings[opstring])
        except Exception as err:
            opstring_vec.append(0)
            # print(err)
    return opstring_vec

# =======================================================
# =======================================================
# =======================================================

with open('../data.json', 'r') as jsonFile:
    data = json.load(jsonFile)

#generating all opcodes
for datarow in data:
    ALL_OPECODES += list(datarow['Opcodes'].keys())
# print(len(ALL_OPECODES))

ALL_OPECODES = sorted(list(set(ALL_OPECODES)))
print('TOTAL OPCODES ' + str(len(ALL_OPECODES)))
print(ALL_OPECODES)
#genrating all strings
for datarow in data:
    ALL_STRINGS += list(datarow['Strings'].keys())
    # print(len(ALL_STRINGS))

ALL_STRINGS = sorted(list(set(ALL_STRINGS)))
# print('TOTAL ALL_STRINGS ' + str(len(ALL_STRINGS)))

pdArr = []
scan_columns = []
appendCols = True
for i in range(len(data)):
    datarow = data[i]
    permission_vec = get_permission_matrix(datarow['Permissions'])
    # print(permission_vec)
    opcode_vec = generate_opcode_vector(datarow['Opcodes'],ALL_OPECODES)
    # print(opcode_vec)
    opstring_vec = generate_opstrings_vector(datarow['Strings'], ALL_STRINGS)
    # print(opstring_vec)

    dictVector = {}
    dictVector['Permissions'] = permission_vec
    dictVector['Opcodes'] = opcode_vec
    dictVector['Strings'] = opstring_vec
    dictVector['VersionCode'] = datarow['VersionCode']
    dictVector['isMalware'] = int(datarow['malware'])
    dictVector['sha1'] = str(datarow['sha1'])

    appendCols = False
    pdArr.append(dictVector)

    scan_columns.append('Permissions')
    scan_columns.append('Opcodes')
    scan_columns.append('Strings')
    scan_columns.append('VersionCode')
    scan_columns.append('isMalware')

df = pd.DataFrame(pdArr, columns=list(set(scan_columns)), dtype=np.float32)
# print(df.head())

df.to_csv('dataframe.csv', index=None, header=True)

y = np.asarray(list(df['isMalware']))
del df['isMalware']


Xp = np.asarray(list(df['Permissions']))
# print(len(Xp[0]))
Xo = np.asarray(list(df['Opcodes']))
# print(len(Xo[0]))
Xs = np.asarray(list(df['Strings']))
# print(len(Xs[0]))

# X = [Xp + Xo + Xs]
X = np.concatenate((Xp, Xo), 1)
X = np.concatenate((X, Xs), 1)

del df['Permissions'], df['Opcodes'], df['Strings']

print(len(df.values))
X = np.concatenate((X, df.values), 1)
print(X[0].shape)
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score

xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True)
print('x')

mlp = SVC(C=1.0, kernel='linear', probability=True, gamma=0.1, tol=0.001)
mlp.fit(xTrain, yTrain)
print("Metrics for Support Vector Machine are as follows")
get_metrics(mlp, xTest, yTest)
print()

clf = AdaBoostClassifier(n_estimators=100, random_state=0)
clf.fit(xTrain, yTrain)
print("Metrics for Ada Boost Classifier are as follows")
get_metrics(clf, xTest, yTest)
print()

rclf = DecisionTreeClassifier(max_depth=20, random_state=0)
rclf.fit(xTrain, yTrain)
print("Metrics for Decision Tree Classifiers are as follows")
get_metrics(rclf, xTest, yTest)
print()

eclf2 = VotingClassifier(estimators=[('svc', mlp), ('adaboost', clf), ('rf', rclf)], voting='soft')
eclf2.fit(X, y)
print("Metrics for Voting Classifier are as follows")
get_metrics(eclf2, xTest, yTest)
print('done')

# -------------------------------------------------------------------------
# -------------------------------------------------------------------------
# -------------------------------------------------------------------------

# ALL_PERMISSIONS = open('../permissions.txt', 'r').readlines()
# ALL_OPECODES_1 = open('../opcodes.txt','r').readlines()
# ALL_OPECODES=[]
# for x in range(len(ALL_OPECODES_1)):
#     ALL_OPECODES.append(ALL_OPECODES_1[x].strip())
# # ALL_OPECODES_1=[]
# ALL_STRINGS = []
# df=[]
# X=[]
# data=""
# with open('../data1.json', 'r') as jsonFile:
#     data = json.load(jsonFile)

# ALL_STRINGS = sorted(list(set(ALL_STRINGS)))
# print('TOTAL ALL_STRINGS ' + str(len(ALL_STRINGS)))

# pdArr = []
# scan_columns = []
# appendCols = True
# for i in range(len(data)):
#     datarow = data[i]
#     permission_vec = get_permission_matrix(datarow['Permissions'])
#     print(permission_vec)
#     opcode_vec = generate_opcode_vector(datarow['Opcodes'],ALL_OPECODES)
#     print(len(opcode_vec))
#     opstring_vec = generate_opstrings_vector(datarow['Strings'], ALL_STRINGS)
#     print(opstring_vec)

#     dictVector = {}
#     dictVector['Permissions'] = permission_vec
#     dictVector['Opcodes'] = opcode_vec
#     dictVector['Strings'] = opstring_vec
#     dictVector['VersionCode'] = datarow['VersionCode']
#     dictVector['isMalware'] = int(datarow['malware'])
#     dictVector['sha1'] = str(datarow['sha1'])

#     appendCols = False
#     pdArr.append(dictVector)

#     scan_columns.append('Permissions')
#     scan_columns.append('Opcodes')
#     scan_columns.append('Strings')
#     scan_columns.append('VersionCode')
#     scan_columns.append('isMalware')

# df = pd.DataFrame(pdArr, columns=list(set(scan_columns)))
# print(df.head())

# df.to_csv('dx.csv', index=None, header=True)

# y = np.asarray(list(df['isMalware']))
# del df['isMalware']


# Xp = np.asarray(list(df['Permissions']))
# print(len(Xp[0]))
# Xo = np.asarray(list(df['Opcodes']))
# print(len(Xo[0]))
# Xs = np.asarray(list(df['Strings']))
# print(len(Xs[0]))

# #X = [Xp + Xo + Xs]
# X = np.concatenate((Xp, Xo), 1)
# X = np.concatenate((X, Xs), 1)

# del df['Permissions'], df['Opcodes'], df['Strings']

# print(len(df.values))
# X = np.concatenate((X, df.values), 1)
# #print(X[4].shape)

# clf = joblib.load('./clf.sav')
# rclf=joblib.load('./rclf.sav')
# mlp=joblib.load('./mlp.sav')
# eclf2=joblib.load('./eclf2.sav')

# y_pred = mlp.predict(X)
# y_p = clf.predict(X)
# y_p1 = rclf.predict(X)
# y_final = eclf2.predict(X)
# print(y_pred)
# print(y_p)
# print(y_p1)
# print(y_final)
# print(y)